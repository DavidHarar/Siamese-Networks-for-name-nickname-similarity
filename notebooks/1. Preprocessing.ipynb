{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyPaL7LiJ97EQGmeK7dHXTVb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Notebook Description\n","This notebook takes the pre-splitted datasets (under the \"restricted\" or the \"mixed\" scenarios), augment new name-nickname pairs like suggested [here](https://www.youtube.com/watch?v=6e65XfwmIWE&t=3s&ab_channel=DynamicVisionandLearningGroup). Then, the texts are tokenized, and the `training`, `validation` and `test` datasets are saved in a matrices format, for later modeling.  \n","Lastly, the data is converted to audio using Google TTS API, and then to spectograms for later modeling."],"metadata":{"id":"ijZ0xjw-x_6t"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7qSSEK-WiEsM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668001091236,"user_tz":-120,"elapsed":26105,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"743c130e-c037-496e-db5f-b276b354378b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import os\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","import random\n","\n","# keras\n","from keras.preprocessing.text import Tokenizer\n","from keras_preprocessing.sequence import pad_sequences\n","\n","# Set options and load file\n","pd.set_option('display.float_format', lambda x: '%.3f' % x)\n","\n","%load_ext google.colab.data_table\n","from google.colab import data_table\n","from google.colab import drive\n","\n","drive.mount('/content/drive')\n","os.chdir(\"YOUR FOLDER HERE\")\n","raw_data_folder = './data/raw/'\n","interim_data_folder = './data/interim/'\n","processed_data_folder = './data/processed/'\n","\n","def shuffle_nicknames(df, times = 4):\n","  # craete a dataframe of false examples, such that if a name appears N_name times,\n","  # then the new dataset will also have it N_name times. \n","  # The fact that names repeats over different nicknames make it impossible to just\n","  # to use shuffle, as eventually some names could end up with its own nicknames\n","  # which eventually induce more noise than signal.\n","  from tqdm import tqdm\n","  import numpy as np\n","\n","  names_in_df = df['name'].drop_duplicates().tolist()\n","  results = pd.DataFrame(columns = ['name','nickname'])\n","\n","  print('Shuffling nicknames..')\n","  for t in tqdm(range(times)):\n","\n","    for j in tqdm(range(len(names_in_df))): \n","      # get name\n","      name = names_in_df[j]\n","\n","      # create two datasets - one with only name, and one of all but name\n","      df_only_name = df[df['name']==name]\n","      N_name = len(df_only_name) # number of examples per name\n","      df_without_name = df[~(df['name']==name)]\n","\n","      # get N_name nicknames\n","      nicknames_of_other_names = df_without_name['nickname'].values\n","      random_index = np.random.randint(0,len(nicknames_of_other_names)-1,N_name)\n","      random_nicknames = nicknames_of_other_names[random_index]\n","\n","      df_only_name['nickname'] = random_nicknames\n","\n","      # store results\n","      results = pd.concat([results, df_only_name],axis=0, ignore_index=True)\n","\n","  # flag positive/negative cases\n","  results['y'] = 0\n","  df['y'] = 1\n","\n","  # add the positive cases as well\n","  results = pd.concat([results, df],axis=0, ignore_index=True)\n","\n","  # Suffle\n","  results = results.sample(frac=1)\n","  \n","  return results\n"]},{"cell_type":"markdown","source":["# Restricted Scenario"],"metadata":{"id":"Cc-h2aY40Nuj"}},{"cell_type":"code","source":["train_df = pd.read_csv(interim_data_folder + 'train_df.csv',index_col=0)\n","validation_df = pd.read_csv(interim_data_folder + 'validation_df.csv',index_col=0)\n","test_df = pd.read_csv(interim_data_folder + 'test_df.csv',index_col=0)\n","\n","print('Training observations (nicknames) before augmentation:', len(train_df))\n","print('Val observations (nicknames) before augmentation:', len(validation_df))\n","print('Test observations (nicknames) before augmentation:', len(test_df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"su4GlgH8x1BV","executionInfo":{"status":"ok","timestamp":1667569816867,"user_tz":-120,"elapsed":17,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"05ba8d86-7818-42e0-acd0-885ba22aa9e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training observations (nicknames) before augmentation: 1508\n","Val observations (nicknames) before augmentation: 286\n","Test observations (nicknames) before augmentation: 202\n"]}]},{"cell_type":"markdown","source":["# Augmentation"],"metadata":{"id":"3FF69WEGigKC"}},{"cell_type":"code","source":["train_df_shuffled = shuffle_nicknames(train_df)\n","validation_df_shuffled = shuffle_nicknames(validation_df)\n","test_df_shuffled = shuffle_nicknames(test_df)\n","\n","print('Training:')\n","print(train_df_shuffled['y'].value_counts())\n","print('Val:')\n","print(validation_df_shuffled['y'].value_counts())\n","print('Test:')\n","print(test_df_shuffled['y'].value_counts())\n","\n","train_df_shuffled.iloc[:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":2300},"id":"F9hx3cVtiZA0","executionInfo":{"status":"ok","timestamp":1667569824677,"user_tz":-120,"elapsed":7825,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"940788d7-8ec3-4aba-89eb-f2b678b4b665"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/575 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","\n","  8%|▊         | 48/575 [00:00<00:01, 472.31it/s]\u001b[A\n"," 17%|█▋        | 96/575 [00:00<00:01, 461.99it/s]\u001b[A\n"," 25%|██▍       | 143/575 [00:00<00:01, 367.80it/s]\u001b[A\n"," 32%|███▏      | 184/575 [00:00<00:01, 380.97it/s]\u001b[A\n"," 39%|███▉      | 224/575 [00:00<00:00, 368.60it/s]\u001b[A\n"," 46%|████▌     | 262/575 [00:00<00:00, 327.79it/s]\u001b[A\n"," 53%|█████▎    | 307/575 [00:00<00:00, 361.51it/s]\u001b[A\n"," 61%|██████▏   | 353/575 [00:00<00:00, 388.42it/s]\u001b[A\n"," 69%|██████▊   | 394/575 [00:01<00:00, 358.34it/s]\u001b[A\n"," 76%|███████▋  | 439/575 [00:01<00:00, 381.89it/s]\u001b[A\n"," 83%|████████▎ | 479/575 [00:01<00:00, 352.50it/s]\u001b[A\n"," 92%|█████████▏| 528/575 [00:01<00:00, 388.77it/s]\u001b[A\n","100%|██████████| 575/575 [00:01<00:00, 375.67it/s]\n"," 25%|██▌       | 1/4 [00:01<00:04,  1.54s/it]\n","  0%|          | 0/575 [00:00<?, ?it/s]\u001b[A\n","  8%|▊         | 44/575 [00:00<00:01, 435.26it/s]\u001b[A\n"," 15%|█▌        | 89/575 [00:00<00:01, 434.91it/s]\u001b[A\n"," 23%|██▎       | 133/575 [00:00<00:01, 421.79it/s]\u001b[A\n"," 31%|███       | 176/575 [00:00<00:01, 395.00it/s]\u001b[A\n"," 38%|███▊      | 216/575 [00:00<00:00, 384.48it/s]\u001b[A\n"," 45%|████▌     | 260/575 [00:00<00:00, 401.55it/s]\u001b[A\n"," 52%|█████▏    | 301/575 [00:00<00:00, 397.40it/s]\u001b[A\n"," 60%|█████▉    | 344/575 [00:00<00:00, 406.96it/s]\u001b[A\n"," 67%|██████▋   | 385/575 [00:00<00:00, 384.73it/s]\u001b[A\n"," 75%|███████▍  | 431/575 [00:01<00:00, 406.45it/s]\u001b[A\n"," 83%|████████▎ | 479/575 [00:01<00:00, 426.27it/s]\u001b[A\n"," 91%|█████████ | 522/575 [00:01<00:00, 298.58it/s]\u001b[A\n","100%|██████████| 575/575 [00:01<00:00, 360.71it/s]\n"," 50%|█████     | 2/4 [00:03<00:03,  1.58s/it]\n","  0%|          | 0/575 [00:00<?, ?it/s]\u001b[A\n","  6%|▌         | 35/575 [00:00<00:01, 345.52it/s]\u001b[A\n"," 12%|█▏        | 70/575 [00:00<00:01, 328.47it/s]\u001b[A\n"," 18%|█▊        | 103/575 [00:00<00:01, 267.48it/s]\u001b[A\n"," 26%|██▌       | 148/575 [00:00<00:01, 329.02it/s]\u001b[A\n"," 32%|███▏      | 183/575 [00:00<00:01, 295.61it/s]\u001b[A\n"," 37%|███▋      | 214/575 [00:00<00:01, 279.47it/s]\u001b[A\n"," 45%|████▍     | 257/575 [00:00<00:00, 321.04it/s]\u001b[A\n"," 51%|█████     | 291/575 [00:00<00:00, 288.99it/s]\u001b[A\n"," 56%|█████▌    | 322/575 [00:01<00:00, 258.32it/s]\u001b[A\n"," 63%|██████▎   | 361/575 [00:01<00:00, 290.77it/s]\u001b[A\n"," 68%|██████▊   | 392/575 [00:01<00:00, 295.69it/s]\u001b[A\n"," 75%|███████▌  | 434/575 [00:01<00:00, 328.21it/s]\u001b[A\n"," 82%|████████▏ | 469/575 [00:01<00:00, 318.20it/s]\u001b[A\n"," 87%|████████▋ | 502/575 [00:01<00:00, 318.49it/s]\u001b[A\n","100%|██████████| 575/575 [00:01<00:00, 304.30it/s]\n"," 75%|███████▌  | 3/4 [00:05<00:01,  1.73s/it]\n","  0%|          | 0/575 [00:00<?, ?it/s]\u001b[A\n","  8%|▊         | 46/575 [00:00<00:01, 453.33it/s]\u001b[A\n"," 16%|█▌        | 92/575 [00:00<00:01, 424.92it/s]\u001b[A\n"," 23%|██▎       | 135/575 [00:00<00:01, 414.66it/s]\u001b[A\n"," 31%|███       | 177/575 [00:00<00:00, 413.32it/s]\u001b[A\n"," 38%|███▊      | 219/575 [00:00<00:00, 370.61it/s]\u001b[A\n"," 46%|████▌     | 262/575 [00:00<00:00, 388.41it/s]\u001b[A\n"," 53%|█████▎    | 302/575 [00:00<00:00, 350.04it/s]\u001b[A\n"," 59%|█████▉    | 340/575 [00:00<00:00, 356.94it/s]\u001b[A\n"," 66%|██████▋   | 382/575 [00:01<00:00, 369.39it/s]\u001b[A\n"," 74%|███████▎  | 424/575 [00:01<00:00, 379.46it/s]\u001b[A\n"," 81%|████████▏ | 468/575 [00:01<00:00, 396.15it/s]\u001b[A\n"," 89%|████████▊ | 509/575 [00:01<00:00, 345.90it/s]\u001b[A\n","100%|██████████| 575/575 [00:01<00:00, 377.27it/s]\n","100%|██████████| 4/4 [00:06<00:00,  1.65s/it]\n"]},{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 115/115 [00:00<00:00, 644.14it/s]\n"," 25%|██▌       | 1/4 [00:00<00:00,  5.31it/s]\n","  0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 115/115 [00:00<00:00, 803.71it/s]\n"," 50%|█████     | 2/4 [00:00<00:00,  5.96it/s]\n","  0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 115/115 [00:00<00:00, 786.28it/s]\n"," 75%|███████▌  | 3/4 [00:00<00:00,  6.15it/s]\n","  0%|          | 0/115 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 115/115 [00:00<00:00, 789.39it/s]\n","100%|██████████| 4/4 [00:00<00:00,  6.08it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","100%|██████████| 77/77 [00:00<00:00, 777.51it/s]\n"," 25%|██▌       | 1/4 [00:00<00:00,  9.03it/s]\n","100%|██████████| 77/77 [00:00<00:00, 934.25it/s]\n","\n","100%|██████████| 77/77 [00:00<00:00, 837.80it/s]\n"," 75%|███████▌  | 3/4 [00:00<00:00, 10.00it/s]\n","  0%|          | 0/77 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 77/77 [00:00<00:00, 653.56it/s]\n","100%|██████████| 4/4 [00:00<00:00,  9.24it/s]"]},{"output_type":"stream","name":"stdout","text":["Training:\n","0    6032\n","1    1508\n","Name: y, dtype: int64\n","Val:\n","0    1144\n","1     286\n","Name: y, dtype: int64\n","Test:\n","0    808\n","1    202\n","Name: y, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["           name nickname  y\n","5554   philinda     issy  0\n","2248    rebecca    court  0\n","4786  katherine     jody  0\n","6785    charles    chuck  1\n","2914     george      kit  0\n","821    lawrence    maxie  0\n","1019   theodore   benjie  0\n","5362       mary      sam  0\n","7254  stephanie    steve  1\n","2319   kathleen      dan  0\n","5030    rosalyn     clay  0\n","2542     mervyn       sy  0\n","383   gwendolyn      wil  0\n","7383     gordon    gordy  1\n","7521      tyron       ty  1"],"text/html":["\n","  <div id=\"df-6de255e5-e534-4cb5-b67b-94f9f03f60c0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>nickname</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5554</th>\n","      <td>philinda</td>\n","      <td>issy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2248</th>\n","      <td>rebecca</td>\n","      <td>court</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4786</th>\n","      <td>katherine</td>\n","      <td>jody</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6785</th>\n","      <td>charles</td>\n","      <td>chuck</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2914</th>\n","      <td>george</td>\n","      <td>kit</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>821</th>\n","      <td>lawrence</td>\n","      <td>maxie</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1019</th>\n","      <td>theodore</td>\n","      <td>benjie</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5362</th>\n","      <td>mary</td>\n","      <td>sam</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7254</th>\n","      <td>stephanie</td>\n","      <td>steve</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2319</th>\n","      <td>kathleen</td>\n","      <td>dan</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5030</th>\n","      <td>rosalyn</td>\n","      <td>clay</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2542</th>\n","      <td>mervyn</td>\n","      <td>sy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>383</th>\n","      <td>gwendolyn</td>\n","      <td>wil</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7383</th>\n","      <td>gordon</td>\n","      <td>gordy</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7521</th>\n","      <td>tyron</td>\n","      <td>ty</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6de255e5-e534-4cb5-b67b-94f9f03f60c0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6de255e5-e534-4cb5-b67b-94f9f03f60c0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6de255e5-e534-4cb5-b67b-94f9f03f60c0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a8bd4d5e58f96183/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 5554,\n            'f': \"5554\",\n        },\n\"philinda\",\n\"issy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2248,\n            'f': \"2248\",\n        },\n\"rebecca\",\n\"court\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4786,\n            'f': \"4786\",\n        },\n\"katherine\",\n\"jody\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 6785,\n            'f': \"6785\",\n        },\n\"charles\",\n\"chuck\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 2914,\n            'f': \"2914\",\n        },\n\"george\",\n\"kit\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 821,\n            'f': \"821\",\n        },\n\"lawrence\",\n\"maxie\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1019,\n            'f': \"1019\",\n        },\n\"theodore\",\n\"benjie\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 5362,\n            'f': \"5362\",\n        },\n\"mary\",\n\"sam\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 7254,\n            'f': \"7254\",\n        },\n\"stephanie\",\n\"steve\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 2319,\n            'f': \"2319\",\n        },\n\"kathleen\",\n\"dan\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 5030,\n            'f': \"5030\",\n        },\n\"rosalyn\",\n\"clay\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2542,\n            'f': \"2542\",\n        },\n\"mervyn\",\n\"sy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 383,\n            'f': \"383\",\n        },\n\"gwendolyn\",\n\"wil\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 7383,\n            'f': \"7383\",\n        },\n\"gordon\",\n\"gordy\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 7521,\n            'f': \"7521\",\n        },\n\"tyron\",\n\"ty\",\n{\n            'v': 1,\n            'f': \"1\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"name\"], [\"string\", \"nickname\"], [\"number\", \"y\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["# save\n","train_df_shuffled.to_csv(interim_data_folder + 'train_df_shuffled.csv')\n","validation_df_shuffled.to_csv(interim_data_folder + 'validation_df_shuffled.csv')\n","test_df_shuffled.to_csv(interim_data_folder + 'test_df_shuffled.csv')\n","\n","# load\n","train_df_shuffled = pd.read_csv(interim_data_folder + 'train_df_shuffled.csv', index_col=0)\n","validation_df_shuffled = pd.read_csv(interim_data_folder + 'validation_df_shuffled.csv', index_col=0)\n","test_df_shuffled = pd.read_csv(interim_data_folder + 'test_df_shuffled.csv', index_col=0)\n"],"metadata":{"id":"el-R0TxqoV-6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize"],"metadata":{"id":"OJIhVL_OyDPN"}},{"cell_type":"code","source":["# Tokenizer\n","names_and_nicknames = list(set(train_df_shuffled['name'].tolist()+ \n","                               validation_df_shuffled['name'].tolist()+ \n","                               test_df_shuffled['name'].tolist()+\n","                               train_df_shuffled['nickname'].tolist()+ \n","                               validation_df_shuffled['nickname'].tolist()+ \n","                               test_df_shuffled['nickname'].tolist()))\n","names_and_nicknames=names_and_nicknames[1:]\n","tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n","tk.fit_on_texts(names_and_nicknames)\n","print(f\"There are {len(tk.word_index)} unique tokens in Train+Val+Test sets.\")\n","tk.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C6tMNXeRyCW1","executionInfo":{"status":"ok","timestamp":1667588956411,"user_tz":-120,"elapsed":264,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"029b940a-8481-49c6-9442-57d19644625b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 29 unique tokens in Train+Val+Test sets.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'UNK': 1,\n"," 'e': 2,\n"," 'a': 3,\n"," 'i': 4,\n"," 'n': 5,\n"," 'l': 6,\n"," 'r': 7,\n"," 's': 8,\n"," 't': 9,\n"," 'o': 10,\n"," 'd': 11,\n"," 'y': 12,\n"," 'c': 13,\n"," 'h': 14,\n"," 'm': 15,\n"," 'b': 16,\n"," 'u': 17,\n"," 'g': 18,\n"," 'k': 19,\n"," 'j': 20,\n"," 'p': 21,\n"," 'f': 22,\n"," 'v': 23,\n"," 'z': 24,\n"," 'w': 25,\n"," 'x': 26,\n"," 'q': 27,\n"," '.': 28,\n"," 'ó': 29}"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["L = [len(x) for x in names_and_nicknames]\n","print(f'Longest name has {max(L)} caracters.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ns2hCLm9yfnp","executionInfo":{"status":"ok","timestamp":1667588960806,"user_tz":-120,"elapsed":249,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"621e0d2a-f028-4fc4-c13c-8909efa5a174"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Longest name has 13 caracters.\n"]}]},{"cell_type":"code","source":["# construct a new vocabulary \n","# --------------------\n","\n","# alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n","alphabet=''.join(list(tk.word_index.keys())).replace('UNK','')\n","print('Alphabet')\n","print(alphabet)\n","print('')\n","\n","char_dict = {}\n","for i, char in enumerate(alphabet):\n","    char_dict[char] = i + 1\n","    \n","# Use char_dict to replace the tk.word_index\n","tk.word_index = char_dict \n","# Add 'UNK' to the vocabulary \n","tk.word_index[tk.oov_token] = max(char_dict.values()) + 1\n","\n","\n","# Extract Targets\n","# -------------------\n","train_targets = train_df_shuffled['y'].values\n","validation_targets = validation_df_shuffled['y'].values\n","test_targets = test_df_shuffled['y'].values\n","\n","\n","# convert names and nicknames into sequences\n","# -------------------\n","\n","train_sequences_names = tk.texts_to_sequences(train_df_shuffled['name'].tolist())\n","train_sequences_nicknames = tk.texts_to_sequences(train_df_shuffled['name'].tolist())\n","validation_sequences_names = tk.texts_to_sequences(validation_df_shuffled['name'].tolist())\n","validation_sequences_nicknames = tk.texts_to_sequences(validation_df_shuffled['name'].tolist())\n","test_sequences_names = tk.texts_to_sequences(test_df_shuffled['name'].tolist())\n","test_sequences_nicknames = tk.texts_to_sequences(test_df_shuffled['name'].tolist())\n","\n","# Padding to 15\n","train_data_names = pad_sequences(train_sequences_names, maxlen=15, padding='post')\n","train_data_nicknames = pad_sequences(train_sequences_nicknames, maxlen=15, padding='post')\n","validation_data_names = pad_sequences(validation_sequences_names, maxlen=15, padding='post')\n","validation_data_nicknames = pad_sequences(validation_sequences_nicknames, maxlen=15, padding='post')\n","test_data_names = pad_sequences(test_sequences_names, maxlen=15, padding='post')\n","test_data_nicknames = pad_sequences(test_sequences_nicknames, maxlen=15, padding='post')\n","\n","# Convert to numpy array\n","train_data_names = np.array(train_data_names)\n","train_data_nicknames = np.array(train_data_nicknames)\n","validation_data_names = np.array(validation_data_names)\n","validation_data_nicknames = np.array(validation_data_nicknames)\n","test_data_names = np.array(test_data_names)\n","test_data_nicknames = np.array(test_data_nicknames)\n","\n","print(train_df_shuffled['name'].tolist()[1])\n","print(train_data_names[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fOHR8dl6y_fj","executionInfo":{"status":"ok","timestamp":1667588965956,"user_tz":-120,"elapsed":250,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"bb4c848d-42ae-4c0f-aafa-574e686f9715"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alphabet\n","eainlrstodychmbugkjpfvzwxq.ó\n","\n","rebecca\n","[ 6  1 15  1 12 12  2  0  0  0  0  0  0  0  0]\n"]}]},{"cell_type":"markdown","source":["**The above `np.array` indexes for each letter in the original string, the index of the apropriate token in `aphabet`.**"],"metadata":{"id":"a_OqTt4Y1_IF"}},{"cell_type":"code","source":["# save data\n","# ----------------\n","\n","np.savetxt(processed_data_folder + 'train_data_names.txt',train_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'train_data_nicknames.txt',train_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_data_names.txt',validation_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_data_nicknames.txt',validation_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_data_names.txt',test_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_data_nicknames.txt',test_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'train_targets.txt',train_targets,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_targets.txt',validation_targets,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_targets.txt',test_targets,fmt='%d')"],"metadata":{"id":"cmOlRnem3bLC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Mixed Scenario"],"metadata":{"id":"fAwtNfmh1Yb9"}},{"cell_type":"code","source":["train_df = pd.read_csv(interim_data_folder + 'train_df_mixed.csv', index_col=0)\n","validation_df = pd.read_csv(interim_data_folder + 'validation_df_mixed.csv', index_col=0)\n","test_df = pd.read_csv(interim_data_folder + 'test_df_mixed.csv', index_col=0)\n","\n","print('Training observations (nicknames) before augmentation:', len(train_df))\n","print('Val observations (nicknames) before augmentation:', len(validation_df))\n","print('Test observations (nicknames) before augmentation:', len(test_df))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cDFzQ1d71aJC","executionInfo":{"status":"ok","timestamp":1667569825784,"user_tz":-120,"elapsed":27,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"0f8fbcef-a79b-4eda-f9e1-09a6d35c13b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training observations (nicknames) before augmentation: 1508\n","Val observations (nicknames) before augmentation: 286\n","Test observations (nicknames) before augmentation: 202\n"]}]},{"cell_type":"markdown","source":["## Augmentation"],"metadata":{"id":"Y3qu5HOD13Al"}},{"cell_type":"code","source":["train_df_shuffled = shuffle_nicknames(train_df)\n","validation_df_shuffled = shuffle_nicknames(validation_df)\n","test_df_shuffled = shuffle_nicknames(test_df)\n","\n","print('Training:')\n","print(train_df_shuffled['y'].value_counts())\n","print('Val:')\n","print(validation_df_shuffled['y'].value_counts())\n","print('Test:')\n","print(test_df_shuffled['y'].value_counts())\n","\n","train_df_shuffled.iloc[:15]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":2033},"executionInfo":{"status":"ok","timestamp":1667569830968,"user_tz":-120,"elapsed":5209,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"5910678f-c61b-4f9a-e225-363579cfdbfe","id":"UdQhUTIm13Al"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/675 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","\n"," 13%|█▎        | 85/675 [00:00<00:00, 848.35it/s]\u001b[A\n"," 25%|██▌       | 170/675 [00:00<00:00, 767.36it/s]\u001b[A\n"," 37%|███▋      | 248/675 [00:00<00:00, 755.13it/s]\u001b[A\n"," 48%|████▊     | 324/675 [00:00<00:00, 735.08it/s]\u001b[A\n"," 60%|█████▉    | 402/675 [00:00<00:00, 750.17it/s]\u001b[A\n"," 71%|███████   | 480/675 [00:00<00:00, 759.53it/s]\u001b[A\n"," 83%|████████▎ | 557/675 [00:00<00:00, 746.50it/s]\u001b[A\n","100%|██████████| 675/675 [00:00<00:00, 751.48it/s]\n"," 25%|██▌       | 1/4 [00:00<00:02,  1.10it/s]\n","  0%|          | 0/675 [00:00<?, ?it/s]\u001b[A\n"," 12%|█▏        | 81/675 [00:00<00:00, 803.76it/s]\u001b[A\n"," 24%|██▍       | 162/675 [00:00<00:00, 765.84it/s]\u001b[A\n"," 35%|███▌      | 239/675 [00:00<00:00, 738.06it/s]\u001b[A\n"," 46%|████▋     | 313/675 [00:00<00:00, 737.64it/s]\u001b[A\n"," 57%|█████▋    | 387/675 [00:00<00:00, 717.66it/s]\u001b[A\n"," 69%|██████▉   | 466/675 [00:00<00:00, 739.14it/s]\u001b[A\n"," 80%|████████  | 541/675 [00:00<00:00, 719.55it/s]\u001b[A\n","100%|██████████| 675/675 [00:00<00:00, 725.79it/s]\n"," 50%|█████     | 2/4 [00:01<00:01,  1.08it/s]\n","  0%|          | 0/675 [00:00<?, ?it/s]\u001b[A\n"," 12%|█▏        | 81/675 [00:00<00:00, 808.64it/s]\u001b[A\n"," 24%|██▍       | 162/675 [00:00<00:00, 740.99it/s]\u001b[A\n"," 35%|███▌      | 239/675 [00:00<00:00, 750.41it/s]\u001b[A\n"," 47%|████▋     | 315/675 [00:00<00:00, 724.43it/s]\u001b[A\n"," 58%|█████▊    | 391/675 [00:00<00:00, 736.44it/s]\u001b[A\n"," 69%|██████▉   | 468/675 [00:00<00:00, 745.67it/s]\u001b[A\n"," 80%|████████  | 543/675 [00:00<00:00, 711.89it/s]\u001b[A\n","100%|██████████| 675/675 [00:00<00:00, 733.99it/s]\n"," 75%|███████▌  | 3/4 [00:02<00:00,  1.07it/s]\n","  0%|          | 0/675 [00:00<?, ?it/s]\u001b[A\n"," 12%|█▏        | 78/675 [00:00<00:00, 771.90it/s]\u001b[A\n"," 23%|██▎       | 156/675 [00:00<00:00, 739.86it/s]\u001b[A\n"," 34%|███▍      | 231/675 [00:00<00:00, 720.79it/s]\u001b[A\n"," 45%|████▌     | 304/675 [00:00<00:00, 714.52it/s]\u001b[A\n"," 56%|█████▌    | 376/675 [00:00<00:00, 708.33it/s]\u001b[A\n"," 67%|██████▋   | 450/675 [00:00<00:00, 716.53it/s]\u001b[A\n"," 77%|███████▋  | 523/675 [00:00<00:00, 718.99it/s]\u001b[A\n","100%|██████████| 675/675 [00:00<00:00, 729.13it/s]\n","100%|██████████| 4/4 [00:03<00:00,  1.07it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n"," 35%|███▍      | 77/222 [00:00<00:00, 760.22it/s]\u001b[A\n","100%|██████████| 222/222 [00:00<00:00, 701.75it/s]\n"," 25%|██▌       | 1/4 [00:00<00:00,  3.10it/s]\n","  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n"," 39%|███▊      | 86/222 [00:00<00:00, 850.47it/s]\u001b[A\n","100%|██████████| 222/222 [00:00<00:00, 797.89it/s]\n"," 50%|█████     | 2/4 [00:00<00:00,  3.31it/s]\n","  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n"," 41%|████▏     | 92/222 [00:00<00:00, 916.90it/s]\u001b[A\n","100%|██████████| 222/222 [00:00<00:00, 792.13it/s]\n"," 75%|███████▌  | 3/4 [00:00<00:00,  3.33it/s]\n","  0%|          | 0/222 [00:00<?, ?it/s]\u001b[A\n"," 38%|███▊      | 85/222 [00:00<00:00, 845.23it/s]\u001b[A\n","100%|██████████| 222/222 [00:00<00:00, 824.16it/s]\n","100%|██████████| 4/4 [00:01<00:00,  3.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Shuffling nicknames..\n"]},{"output_type":"stream","name":"stderr","text":["  0%|          | 0/4 [00:00<?, ?it/s]\n","  0%|          | 0/163 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 163/163 [00:00<00:00, 875.21it/s]\n"," 25%|██▌       | 1/4 [00:00<00:00,  5.09it/s]\n","  0%|          | 0/163 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 163/163 [00:00<00:00, 856.83it/s]\n"," 50%|█████     | 2/4 [00:00<00:00,  5.01it/s]\n","  0%|          | 0/163 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 163/163 [00:00<00:00, 865.41it/s]\n"," 75%|███████▌  | 3/4 [00:00<00:00,  5.02it/s]\n","  0%|          | 0/163 [00:00<?, ?it/s]\u001b[A\n","100%|██████████| 163/163 [00:00<00:00, 739.26it/s]\n","100%|██████████| 4/4 [00:00<00:00,  4.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Training:\n","0    6032\n","1    1508\n","Name: y, dtype: int64\n","Val:\n","0    1144\n","1     286\n","Name: y, dtype: int64\n","Test:\n","0    808\n","1    202\n","Name: y, dtype: int64\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"execute_result","data":{"text/plain":["            name nickname  y\n","4918    theodore       cy  0\n","4225       flora    belle  0\n","6871    isabella      bel  1\n","1136          jo      ara  0\n","1754     clement   jessie  0\n","464      vanessa     eddy  0\n","3391    samantha   connie  0\n","126        edwin    ginny  0\n","6576   ferdinand    nandy  1\n","7284       edwin      ned  1\n","529         anne  shloime  0\n","4977      alexis    cindy  0\n","2026  jacqueline     issy  0\n","4318       basil    mandy  0\n","520      derrick    clara  0"],"text/html":["\n","  <div id=\"df-ba012f79-c244-4b48-8c2f-5d6453f18fcf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>nickname</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>4918</th>\n","      <td>theodore</td>\n","      <td>cy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4225</th>\n","      <td>flora</td>\n","      <td>belle</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6871</th>\n","      <td>isabella</td>\n","      <td>bel</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1136</th>\n","      <td>jo</td>\n","      <td>ara</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1754</th>\n","      <td>clement</td>\n","      <td>jessie</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>464</th>\n","      <td>vanessa</td>\n","      <td>eddy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3391</th>\n","      <td>samantha</td>\n","      <td>connie</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>edwin</td>\n","      <td>ginny</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6576</th>\n","      <td>ferdinand</td>\n","      <td>nandy</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7284</th>\n","      <td>edwin</td>\n","      <td>ned</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>529</th>\n","      <td>anne</td>\n","      <td>shloime</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4977</th>\n","      <td>alexis</td>\n","      <td>cindy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2026</th>\n","      <td>jacqueline</td>\n","      <td>issy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4318</th>\n","      <td>basil</td>\n","      <td>mandy</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>520</th>\n","      <td>derrick</td>\n","      <td>clara</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba012f79-c244-4b48-8c2f-5d6453f18fcf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-ba012f79-c244-4b48-8c2f-5d6453f18fcf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-ba012f79-c244-4b48-8c2f-5d6453f18fcf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"application/vnd.google.colaboratory.module+javascript":"\n      import \"https://ssl.gstatic.com/colaboratory/data_table/a8bd4d5e58f96183/data_table.js\";\n\n      window.createDataTable({\n        data: [[{\n            'v': 4918,\n            'f': \"4918\",\n        },\n\"theodore\",\n\"cy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4225,\n            'f': \"4225\",\n        },\n\"flora\",\n\"belle\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 6871,\n            'f': \"6871\",\n        },\n\"isabella\",\n\"bel\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 1136,\n            'f': \"1136\",\n        },\n\"jo\",\n\"ara\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 1754,\n            'f': \"1754\",\n        },\n\"clement\",\n\"jessie\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 464,\n            'f': \"464\",\n        },\n\"vanessa\",\n\"eddy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 3391,\n            'f': \"3391\",\n        },\n\"samantha\",\n\"connie\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 126,\n            'f': \"126\",\n        },\n\"edwin\",\n\"ginny\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 6576,\n            'f': \"6576\",\n        },\n\"ferdinand\",\n\"nandy\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 7284,\n            'f': \"7284\",\n        },\n\"edwin\",\n\"ned\",\n{\n            'v': 1,\n            'f': \"1\",\n        }],\n [{\n            'v': 529,\n            'f': \"529\",\n        },\n\"anne\",\n\"shloime\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4977,\n            'f': \"4977\",\n        },\n\"alexis\",\n\"cindy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 2026,\n            'f': \"2026\",\n        },\n\"jacqueline\",\n\"issy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 4318,\n            'f': \"4318\",\n        },\n\"basil\",\n\"mandy\",\n{\n            'v': 0,\n            'f': \"0\",\n        }],\n [{\n            'v': 520,\n            'f': \"520\",\n        },\n\"derrick\",\n\"clara\",\n{\n            'v': 0,\n            'f': \"0\",\n        }]],\n        columns: [[\"number\", \"index\"], [\"string\", \"name\"], [\"string\", \"nickname\"], [\"number\", \"y\"]],\n        columnOptions: [{\"width\": \"1px\", \"className\": \"index_column\"}],\n        rowsPerPage: 25,\n        helpUrl: \"https://colab.research.google.com/notebooks/data_table.ipynb\",\n        suppressOutputScrolling: true,\n        minimumWidth: undefined,\n      });\n    "},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# save\n","train_df_shuffled.to_csv(interim_data_folder + 'train_df_mixed_shuffled.csv')\n","validation_df_shuffled.to_csv(interim_data_folder + 'validation_df_mixed_shuffled.csv')\n","test_df_shuffled.to_csv(interim_data_folder + 'test_df_mixed_shuffled.csv')\n","\n","# load\n","train_df_shuffled = pd.read_csv(interim_data_folder + 'train_df_mixed_shuffled.csv', index_col=0)\n","validation_df_shuffled = pd.read_csv(interim_data_folder + 'validation_df_mixed_shuffled.csv', index_col=0)\n","test_df_shuffled = pd.read_csv(interim_data_folder + 'test_df_mixed_shuffled.csv', index_col=0)\n"],"metadata":{"id":"ZyvF-Rul2Dpm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Tokenize"],"metadata":{"id":"u2ak4-Ry2bie"}},{"cell_type":"code","source":["# Tokenizer\n","names_and_nicknames = list(set(train_df_shuffled['name'].tolist()+ \n","                               validation_df_shuffled['name'].tolist()+ \n","                               test_df_shuffled['name'].tolist()+\n","                               train_df_shuffled['nickname'].tolist()+ \n","                               validation_df_shuffled['nickname'].tolist()+ \n","                               test_df_shuffled['nickname'].tolist()))\n","names_and_nicknames=names_and_nicknames[1:]\n","tk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n","tk.fit_on_texts(names_and_nicknames)\n","print(f\"There are {len(tk.word_index)} unique tokens in Train+Val+Test sets.\")\n","tk.word_index"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667569830968,"user_tz":-120,"elapsed":10,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"daf236bf-0701-4ab2-e5c8-070dedc36663","id":"jL2N1BYk2bie"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["There are 29 unique tokens in Train+Val+Test sets.\n"]},{"output_type":"execute_result","data":{"text/plain":["{'UNK': 1,\n"," 'e': 2,\n"," 'a': 3,\n"," 'i': 4,\n"," 'n': 5,\n"," 'l': 6,\n"," 'r': 7,\n"," 's': 8,\n"," 'o': 9,\n"," 't': 10,\n"," 'd': 11,\n"," 'y': 12,\n"," 'c': 13,\n"," 'h': 14,\n"," 'm': 15,\n"," 'b': 16,\n"," 'u': 17,\n"," 'g': 18,\n"," 'k': 19,\n"," 'j': 20,\n"," 'p': 21,\n"," 'f': 22,\n"," 'v': 23,\n"," 'z': 24,\n"," 'w': 25,\n"," 'x': 26,\n"," 'q': 27,\n"," '.': 28,\n"," 'ó': 29}"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["L = [len(x) for x in names_and_nicknames]\n","print(f'Longest name has {max(L)} caracters.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667569830972,"user_tz":-120,"elapsed":13,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"79ea4daa-f611-46a2-d1e7-a6b230d1d11c","id":"DBxuqK6f2bie"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Longest name has 13 caracters.\n"]}]},{"cell_type":"code","source":["# construct a new vocabulary \n","# --------------------\n","\n","# alphabet=\"abcdefghijklmnopqrstuvwxyz0123456789-,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\n","alphabet=''.join(list(tk.word_index.keys())).replace('UNK','')\n","print('Alphabet')\n","print(alphabet)\n","print('')\n","\n","char_dict = {}\n","for i, char in enumerate(alphabet):\n","    char_dict[char] = i + 1\n","    \n","# Use char_dict to replace the tk.word_index\n","tk.word_index = char_dict \n","# Add 'UNK' to the vocabulary \n","tk.word_index[tk.oov_token] = max(char_dict.values()) + 1\n","\n","\n","# Extract Targets\n","# -------------------\n","train_targets = train_df_shuffled['y'].values\n","validation_targets = validation_df_shuffled['y'].values\n","test_targets = test_df_shuffled['y'].values\n","\n","\n","# convert names and nicknames into sequences\n","# -------------------\n","\n","train_sequences_names = tk.texts_to_sequences(train_df_shuffled['name'].tolist())\n","train_sequences_nicknames = tk.texts_to_sequences([str(x) for x in train_df_shuffled['nickname'].tolist()])\n","validation_sequences_names = tk.texts_to_sequences(validation_df_shuffled['name'].tolist())\n","validation_sequences_nicknames = tk.texts_to_sequences(validation_df_shuffled['nickname'].tolist())\n","test_sequences_names = tk.texts_to_sequences(test_df_shuffled['name'].tolist())\n","test_sequences_nicknames = tk.texts_to_sequences(test_df_shuffled['nickname'].tolist())\n","\n","# Padding to 15\n","train_data_names = pad_sequences(train_sequences_names, maxlen=15, padding='post')\n","train_data_nicknames = pad_sequences(train_sequences_nicknames, maxlen=15, padding='post')\n","validation_data_names = pad_sequences(validation_sequences_names, maxlen=15, padding='post')\n","validation_data_nicknames = pad_sequences(validation_sequences_nicknames, maxlen=15, padding='post')\n","test_data_names = pad_sequences(test_sequences_names, maxlen=15, padding='post')\n","test_data_nicknames = pad_sequences(test_sequences_nicknames, maxlen=15, padding='post')\n","\n","# Convert to numpy array\n","train_data_names = np.array(train_data_names)\n","train_data_nicknames = np.array(train_data_nicknames)\n","validation_data_names = np.array(validation_data_names)\n","validation_data_nicknames = np.array(validation_data_nicknames)\n","test_data_names = np.array(test_data_names)\n","test_data_nicknames = np.array(test_data_nicknames)\n","\n","print(train_df_shuffled['name'].tolist()[1])\n","print(train_data_names[1])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1667569831688,"user_tz":-120,"elapsed":726,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"64b19b7e-e542-4480-dbd8-3bda4dafa6b1","id":"A1ayGtbm2bif"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Alphabet\n","eainlrsotdychmbugkjpfvzwxq.ó\n","\n","flora\n","[21  5  8  6  2  0  0  0  0  0  0  0  0  0  0]\n"]}]},{"cell_type":"code","source":["print(train_df_shuffled['name'].iloc[:5],'\\n')\n","print(train_df_shuffled['nickname'].iloc[:5],'\\n\\n')\n","\n","print(train_data_names[:5],'\\n')\n","print(train_data_nicknames[:5],'\\n\\n')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69egf3KkwHHD","executionInfo":{"status":"ok","timestamp":1667569831689,"user_tz":-120,"elapsed":7,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"b37ce551-71c8-4443-b265-3d1d302bb80b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["4918    theodore\n","4225       flora\n","6871    isabella\n","1136          jo\n","1754     clement\n","Name: name, dtype: object \n","\n","4918        cy\n","4225     belle\n","6871       bel\n","1136       ara\n","1754    jessie\n","Name: nickname, dtype: object \n","\n","\n","[[ 9 13  1  8 10  8  6  1  0  0  0  0  0  0  0]\n"," [21  5  8  6  2  0  0  0  0  0  0  0  0  0  0]\n"," [ 3  7  2 15  1  5  5  2  0  0  0  0  0  0  0]\n"," [19  8  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [12  5  1 14  1  4  9  0  0  0  0  0  0  0  0]] \n","\n","[[12 11  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [15  1  5  5  1  0  0  0  0  0  0  0  0  0  0]\n"," [15  1  5  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 2  6  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [19  1  7  7  3  1  0  0  0  0  0  0  0  0  0]] \n","\n","\n"]}]},{"cell_type":"markdown","source":["**The above `np.array` indexes for each letter in the original string, the index of the apropriate token in `aphabet`.**"],"metadata":{"id":"y-8iPbLG2bif"}},{"cell_type":"code","source":["# save data\n","# ----------------\n","\n","np.savetxt(processed_data_folder + 'train_mixed_data_names.txt',train_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'train_mixed_data_nicknames.txt',train_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_mixed_data_names.txt',validation_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_mixed_data_nicknames.txt',validation_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_mixed_data_names.txt',test_data_names,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_mixed_data_nicknames.txt',test_data_nicknames,fmt='%d')\n","np.savetxt(processed_data_folder + 'train_mixed_targets.txt',train_targets,fmt='%d')\n","np.savetxt(processed_data_folder + 'validation_mixed_targets.txt',validation_targets,fmt='%d')\n","np.savetxt(processed_data_folder + 'test_mixed_targets.txt',test_targets,fmt='%d')"],"metadata":{"id":"qS_UCFFg2bif"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Convert to Sound\n","The part below takes a lot of time for competion, so it was ran but commented out. The files in the appropriate folders.\n","\n","**NOTE TO SELF - IT HAS EITHER TO BE RAN AGAIN, OR THE ORIGINAL SPLITS' FILES SHOULD BE THE ONES IN THE FOLDERS.**"],"metadata":{"id":"eDYJhoV2I3ve"}},{"cell_type":"code","source":["!pip install gtts"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RbiaGAW6cej2","executionInfo":{"status":"ok","timestamp":1668001102274,"user_tz":-120,"elapsed":4603,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"04a3c606-19dc-4f31-d330-7aa338a4542e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gtts\n","  Downloading gTTS-2.2.4-py3-none-any.whl (26 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gtts) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from gtts) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gtts) (1.15.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gtts) (2022.9.24)\n","Installing collected packages: gtts\n","Successfully installed gtts-2.2.4\n"]}]},{"cell_type":"code","source":["# load\n","train_df_shuffled = pd.read_csv(interim_data_folder + 'train_df_shuffled.csv', index_col=0)\n","validation_df_shuffled = pd.read_csv(interim_data_folder + 'validation_df_shuffled.csv', index_col=0)\n","test_df_shuffled = pd.read_csv(interim_data_folder + 'test_df_shuffled.csv', index_col=0)\n"],"metadata":{"id":"DywncnYc7kMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from gtts import gTTS\n","\n","# Prepare repositories\n","# ---------------------\n","# os.mkdir(interim_data_folder + '/mixed_datasets_audio/')\n","# os.mkdir(interim_data_folder + '/mixed_datasets_audio/train/')\n","# os.mkdir(interim_data_folder + '/mixed_datasets_audio/validation/')\n","# os.mkdir(interim_data_folder + '/mixed_datasets_audio/test')\n","\n","# # Training\n","# # -------------------\n","# train_names = train_df_shuffled['name'].tolist()\n","# train_nicknames = train_df_shuffled['nickname'].tolist()\n","\n","# start = 1116+1038 + 1085+1044 + 1040 + 1037 + 1014\n","\n","# # Train\n","# # -------------------\n","\n","# for j in tqdm(range(start,len(train_df_shuffled))):\n","#   name_temp = train_names[j]\n","#   nickname_temp = train_nicknames[j]\n","#   if str(nickname_temp)=='nan':\n","#     nickname_temp = train_nicknames[j-1]\n","#     print('NA nickname detected at ', j)\n","  \n","#   name_job = gTTS(text=name_temp, lang='en', slow=False)\n","#   name_job.save(interim_data_folder + f\"mixed_datasets_audio/train/name_{j}.mp3\")\n","\n","#   nickname_job = gTTS(text=nickname_temp, lang='en', slow=False)\n","#   nickname_job.save(interim_data_folder + f\"mixed_datasets_audio/train/nickname_{j}.mp3\")\n"," \n","# # Validation\n","# # -------------------\n","# validation_names = validation_df_shuffled['name'].tolist()\n","# validation_nicknames = validation_df_shuffled['nickname'].tolist()\n","\n","# start=874\n","\n","# for j in tqdm(range(start, len(validation_df_shuffled))):\n","#   name_temp = validation_names[j]\n","#   nickname_temp = validation_nicknames[j]\n","  \n","#   if str(nickname_temp)=='nan':\n","#     nickname_temp = validation_nicknames[j-1]\n","#     print('NA nickname detected at ', j)\n","  \n","#   name_job = gTTS(text=name_temp, lang='en', slow=False)\n","#   name_job.save(interim_data_folder + f\"mixed_datasets_audio/validation/name_{j}.mp3\")\n","\n","#   nickname_job = gTTS(text=nickname_temp, lang='en', slow=False)\n","#   nickname_job.save(interim_data_folder + f\"mixed_datasets_audio/validation/nickname_{j}.mp3\")\n","\n","# # Test\n","# # -------------------\n","# test_names = test_df_shuffled['name'].tolist()\n","# test_nicknames = test_df_shuffled['nickname'].tolist()\n","\n","# start=0\n","\n","# for j in tqdm(range(start, len(test_df_shuffled))):\n","#   name_temp = test_names[j]\n","#   nickname_temp = test_nicknames[j]\n","  \n","#   if str(nickname_temp)=='nan':\n","#     nickname_temp = test_nicknames[j-1]\n","#     print('NA nickname detected at ', j)\n","\n","#   name_job = gTTS(text=name_temp, lang='en', slow=False)\n","#   name_job.save(interim_data_folder + f\"mixed_datasets_audio/test/name_{j}.mp3\")\n","\n","#   nickname_job = gTTS(text=nickname_temp, lang='en', slow=False)\n","#   nickname_job.save(interim_data_folder + f\"mixed_datasets_audio/test/nickname_{j}.mp3\")\n"," \n"],"metadata":{"id":"7exK7hOPs4aN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1668001390175,"user_tz":-120,"elapsed":269615,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"bffef151-e0be-4ae8-d684-59c6083efffe"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 1010/1010 [04:29<00:00,  3.75it/s]\n"]}]},{"cell_type":"markdown","source":["# Convert Audio Files into Metrices"],"metadata":{"id":"BDIAvahOpipT"}},{"cell_type":"code","source":["import librosa\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","def load_audio(path):\n","    \"\"\"\n","    Load and pad an audio example\n","    \"\"\"\n","    import librosa\n","    import numpy as np\n","\n","    def zero_padding(mat, length=80):\n","      import numpy as np\n","      n,m = mat.shape\n","      zero_mat = np.zeros((n,length-m))\n","\n","      return np.concatenate((mat,zero_mat),axis=1)\n","\n","    # load\n","    values, sampling_rate = librosa.load(path)\n","\n","    # pad\n","    mat = librosa.feature.melspectrogram(y=values, sr=sampling_rate)\n","    padded_mat = zero_padding(mat,80)\n","\n","    return padded_mat\n"],"metadata":{"id":"6PtthORlqYy8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_names_mat = []\n","train_nicknames_mat = []\n","\n","validation_names_mat = []\n","validation_nicknames_mat = []\n","\n","test_names_mat = []\n","test_nicknames_mat = []\n","\n","for j in tqdm(range(len(train_df_shuffled))):\n","  train_names_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/train/name_{j}.mp3\"))\n","  train_nicknames_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/train/nickname_{j}.mp3\"))\n","\n","for j in tqdm(range(len(validation_df_shuffled))):\n","  validation_names_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/validation/name_{j}.mp3\"))\n","  validation_nicknames_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/validation/nickname_{j}.mp3\"))\n","\n","for j in tqdm(range(len(test_df_shuffled))):\n","  test_names_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/test/name_{j}.mp3\"))\n","  test_nicknames_mat.append(load_audio(interim_data_folder + f\"mixed_datasets_audio/test/nickname_{j}.mp3\"))\n","\n","\n","train_names_mat = np.array(train_names_mat, dtype=np.float32)\n","train_nicknames_mat = np.array(train_nicknames_mat, dtype=np.float32)\n","\n","validation_names_mat = np.array(validation_names_mat, dtype=np.float32)\n","validation_nicknames_mat = np.array(validation_nicknames_mat, dtype=np.float32)\n","\n","test_names_mat = np.array(test_names_mat, dtype=np.float32)\n","test_nicknames_mat = np.array(test_nicknames_mat, dtype=np.float32)\n","\n","print(train_names_mat.shape)\n","print(train_nicknames_mat.shape)\n","print(validation_names_mat.shape)\n","print(validation_nicknames_mat.shape)\n","print(test_names_mat.shape)\n","print(test_nicknames_mat.shape)\n","\n","np.save(processed_data_folder + 'train_names_mat.npy', train_names_mat) \n","np.save(processed_data_folder + 'train_nicknames_mat.npy', train_nicknames_mat) \n","np.save(processed_data_folder + 'validation_names_mat.npy', validation_names_mat) \n","np.save(processed_data_folder + 'validation_nicknames_mat.npy', validation_nicknames_mat) \n","np.save(processed_data_folder + 'test_names_mat.npy', test_names_mat) \n","np.save(processed_data_folder + 'test_nicknames_mat.npy', test_nicknames_mat) \n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kiNqbioebDJU","executionInfo":{"status":"ok","timestamp":1668008120234,"user_tz":-120,"elapsed":5980560,"user":{"displayName":"David Harar","userId":"00774606951973702222"}},"outputId":"f34d705c-941c-45fb-dc46-8844ebd70822"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 7540/7540 [1:17:45<00:00,  1.62it/s]\n","100%|██████████| 1430/1430 [15:24<00:00,  1.55it/s]\n","100%|██████████| 1010/1010 [06:23<00:00,  2.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["(7540, 128, 80)\n","(7540, 128, 80)\n","(1430, 128, 80)\n","(1430, 128, 80)\n","(1010, 128, 80)\n","(1010, 128, 80)\n"]}]}]}